{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clone the repo\n",
    "!git clone https://github.com/Sarthak16082/DDT\n",
    "# cd into DDT\n",
    "%cd DDT\n",
    "\n",
    "!pip install lightning==2.5.0 torch torchvision torchaudio pyyaml diffusers timm\n",
    "\n",
    "\n",
    "!wget https://huggingface.co/MCG-NJU/DDT-XL-22en6de-R512/resolve/main/model.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from src.diffusion.base.guidance import simple_guidance_fn\n",
    "from src.diffusion.stateful_flow_matching.scheduling import LinearScheduler\n",
    "from src.diffusion.stateful_flow_matching.sampling import EulerSampler\n",
    "\n",
    "# Helper Functions\n",
    "\n",
    "def instantiate_from_config(config):\n",
    "    module_path, class_name = config[\"class_path\"].rsplit(\".\", 1)\n",
    "    module = __import__(module_path, fromlist=[class_name])\n",
    "    return getattr(module, class_name)(**config.get(\"init_args\", {}))\n",
    "\n",
    "def load_weights(model, checkpoint, prefix=\"ema_denoiser.\"):\n",
    "    state_dict = checkpoint[\"state_dict\"]\n",
    "    loaded, total = 0, len(model.state_dict())\n",
    "    for name, param in model.state_dict().items():\n",
    "        full_name = prefix + name\n",
    "        if full_name in state_dict:\n",
    "            try:\n",
    "                param.copy_(state_dict[full_name])\n",
    "                loaded += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load {full_name}: {e}\")\n",
    "        else:\n",
    "            print(f\"Missing key in checkpoint: {full_name}\")\n",
    "    print(f\"Loaded {loaded}/{total} weights.\")\n",
    "    return model\n",
    "\n",
    "def tensor_to_image(x):\n",
    "    if x is None:\n",
    "        raise ValueError(\"Input tensor is None\")\n",
    "    x = torch.clamp((x + 1.0) * 127.5 + 0.5, 0, 255).to(torch.uint8)\n",
    "    return x\n",
    "\n",
    "def parse_class_labels(filename=\"imagenet_classlabels.txt\"):\n",
    "    label_map = {}\n",
    "    try:\n",
    "        with open(filename, \"r\") as f:\n",
    "            for line in f:\n",
    "                match = re.match(r'\\|\\s*(\\d+)\\s*\\|\\s*(.*?)\\s*\\|', line)\n",
    "                if match:\n",
    "                    label_map[match.group(2).strip().lower()] = int(match.group(1))\n",
    "    except FileNotFoundError:\n",
    "        print(\"Label file not found.\")\n",
    "        exit()\n",
    "    return label_map\n",
    "\n",
    "# Settings\n",
    "\n",
    "config_path = \"configs/repa_improved_ddt_xlen22de6_512.yaml\"\n",
    "checkpoint_path = \"model.ckpt\"\n",
    "output_dir = \"outputs_improved_v6\"\n",
    "classes = [\"tiger cat\"]\n",
    "resolution = 512\n",
    "num_images = 2\n",
    "seed = 1234\n",
    "\n",
    "# Sampler parameters\n",
    "num_steps = 100\n",
    "guidance = 8.5\n",
    "guidance_min, guidance_max = 0.02, 0.98\n",
    "last_step, timeshift = 0.005, 0.9\n",
    "\n",
    "# Prepare environment\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load configuration and models\n",
    "cfg = OmegaConf.load(config_path)\n",
    "vae = instantiate_from_config(cfg.model.vae)\n",
    "denoiser = instantiate_from_config(cfg.model.denoiser)\n",
    "conditioner = instantiate_from_config(cfg.model.conditioner)\n",
    "\n",
    "# Load weights\n",
    "print(f\"Loading weights from {checkpoint_path}...\")\n",
    "ckpt = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "denoiser = load_weights(denoiser, ckpt).to(device).eval()\n",
    "vae = vae.to(device).eval()\n",
    "\n",
    "# Use multiple GPUs if available\n",
    "if torch.cuda.device_count() > 1:\n",
    "    denoiser = torch.nn.DataParallel(denoiser)\n",
    "\n",
    "# Set up sampler\n",
    "sampler = EulerSampler(\n",
    "    scheduler=LinearScheduler(),\n",
    "    w_scheduler=LinearScheduler(),\n",
    "    guidance_fn=simple_guidance_fn,\n",
    "    num_steps=num_steps,\n",
    "    guidance=guidance,\n",
    "    state_refresh_rate=1,\n",
    "    guidance_interval_min=guidance_min,\n",
    "    guidance_interval_max=guidance_max,\n",
    "    timeshift=timeshift,\n",
    "    last_step=last_step\n",
    ")\n",
    "\n",
    "# Process class names\n",
    "label_map = parse_class_labels()\n",
    "valid_classes = [cls for cls in classes if cls.lower() in label_map]\n",
    "\n",
    "# Image Gen\n",
    "\n",
    "for class_name in valid_classes:\n",
    "    class_id = label_map[class_name.lower()]\n",
    "    print(f\"\\nGenerating images for: {class_name} (ID: {class_id})\")\n",
    "    for i in range(num_images):\n",
    "        img_seed = seed + i * 10\n",
    "        generator = torch.Generator().manual_seed(img_seed)\n",
    "        noise = torch.randn((1, 4, resolution // 8, resolution // 8), generator=generator).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            cond, uncond = conditioner([class_id])\n",
    "            output = sampler(denoiser, noise, cond.to(device), uncond.to(device))\n",
    "            if output is None:\n",
    "                print(f\"Sampler failed for {class_name}, seed {img_seed}\")\n",
    "                continue\n",
    "            decoded = vae.decode(output.to(device))\n",
    "            if decoded is None:\n",
    "                print(f\"Decoding failed for {class_name}, seed {img_seed}\")\n",
    "                continue\n",
    "\n",
    "            img_tensor = tensor_to_image(decoded.cpu())[0].permute(1, 2, 0).numpy()\n",
    "            img_tensor = img_tensor[:, :, :3] if img_tensor.shape[2] > 3 else img_tensor\n",
    "\n",
    "            img = Image.fromarray(img_tensor)\n",
    "            fname = f\"{class_name.replace(' ', '_')}_seed{img_seed}.png\"\n",
    "            img.save(os.path.join(output_dir, fname))\n",
    "            print(f\"Saved: {fname}\")\n",
    "\n",
    "            # Optional visualization\n",
    "            plt.imshow(np.clip(decoded[0].cpu().permute(1, 2, 0).numpy(), 0, 1))\n",
    "            plt.axis('off')\n",
    "            plt.title(f\"{class_name} (Seed: {img_seed})\")\n",
    "            plt.savefig(os.path.join(output_dir, f\"{class_name.replace(' ', '_')}_raw_seed{img_seed}.png\"))\n",
    "            plt.close()\n",
    "\n",
    "print(\"\\nAll done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
