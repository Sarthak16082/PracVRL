{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# clone the repo\n",
    "#!git clone https://github.com/Sarthak16082/DDT\n",
    "# cd into DDT\n",
    "#%cd DDT\n",
    "\n",
    "#!pip install lightning==2.5.0 torch torchvision torchaudio pyyaml diffusers timm\n",
    "#!wget https://huggingface.co/MCG-NJU/DDT-XL-22en6de-R512/resolve/main/model.ckpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"use your token here\") #it streams ImageNet, so you gotta use HF_token after getting the permission for ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Install dependencies\n",
    "#!pip install datasets\n",
    "%cd DDT\n",
    "\n",
    "OUTPUT_DIR = \"extracted_features_21\"\n",
    "# \n",
    "import os, sys, yaml, copy, gc, logging, torch, torchvision.transforms as T\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "from src.lightning_model import LightningModel as MyLightningModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import login\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from glob import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Clear memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Add repo root to Python path\n",
    "sys.path.insert(0, os.getcwd())\n",
    "\n",
    "# helpers\n",
    "def instantiate(cfg):\n",
    "    if not isinstance(cfg, dict) or \"class_path\" not in cfg:\n",
    "        raise ValueError(\"Config must have a 'class_path'\")\n",
    "    module_path, cls_name = cfg[\"class_path\"].rsplit(\".\", 1)\n",
    "    module = __import__(module_path, fromlist=[cls_name])\n",
    "    return getattr(module, cls_name)(**cfg.get(\"init_args\", {}))\n",
    "\n",
    "# load config and components\n",
    "with open(\"configs/repa_improved_ddt_xlen22de6_512.yaml\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "print(\"Instantiating model parts...\")\n",
    "vae = instantiate(cfg[\"model\"][\"vae\"])\n",
    "cond = instantiate(cfg[\"model\"][\"conditioner\"])\n",
    "den = instantiate(cfg[\"model\"][\"denoiser\"])\n",
    "\n",
    "# shared scheduler\n",
    "sched_path = (cfg[\"model\"][\"diffusion_trainer\"][\"init_args\"]\n",
    "              .get(\"scheduler\") or cfg[\"model\"][\"diffusion_sampler\"][\"init_args\"].get(\"scheduler\"))\n",
    "assert isinstance(sched_path, str)\n",
    "sched = instantiate({\"class_path\": sched_path, \"init_args\": {}})\n",
    "\n",
    "# Deep copy to preserve original config details\n",
    "trainer_cfg = copy.deepcopy(cfg[\"model\"][\"diffusion_trainer\"])\n",
    "trainer_cfg[\"init_args\"][\"scheduler\"] = sched\n",
    "trainer = instantiate(trainer_cfg)\n",
    "\n",
    "sampler_cfg = copy.deepcopy(cfg[\"model\"][\"diffusion_sampler\"])\n",
    "sampler_cfg[\"init_args\"][\"scheduler\"] = sched\n",
    "sampler = instantiate(sampler_cfg)\n",
    "\n",
    "# load lightning model\n",
    "assert os.path.isfile(\"model.ckpt\"), \"Checkpoint not found.\"\n",
    "model_cpu = MyLightningModel.load_from_checkpoint(\n",
    "    \"model.ckpt\", map_location=\"cpu\",\n",
    "    vae=vae, conditioner=cond,\n",
    "    denoiser=den, diffusion_trainer=trainer,\n",
    "    diffusion_sampler=sampler, strict=False\n",
    ")\n",
    "print(\"Loaded checkpoint on CPU\")\n",
    "\n",
    "# move to muGPU(s) if available\n",
    "if torch.cuda.is_available():\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model_cpu).to(device)\n",
    "        model.module.eval()\n",
    "        model.module.freeze()\n",
    "    else:\n",
    "        model = model_cpu.to(device)\n",
    "        model.eval()\n",
    "        model.freeze()\n",
    "else:\n",
    "    model = model_cpu\n",
    "    model.eval()\n",
    "    model.freeze()\n",
    "\n",
    "print(f\"Model ready on {device}\")\n",
    "\n",
    "ddt = model.module.denoiser if isinstance(model, nn.DataParallel) else model.denoiser\n",
    "vae = model.module.vae if isinstance(model, nn.DataParallel) else model.vae\n",
    "print(f\"DDT model device: {next(ddt.parameters()).device}\")\n",
    "\"\"\"\n",
    "#not applicable for the correct timestep\n",
    "x = torch.randn(1, 4, 64, 64, device=device)\n",
    "t = torch.randint(0, 1000, (1,), device=device)\n",
    "y = torch.randint(0, 1000, (1,), device=device)\n",
    "\"\"\"\n",
    "feat = {}\n",
    "def hook(m, i, o): feat[\"f\"] = (o[0] if isinstance(o, tuple) else o).detach()\n",
    "layer = ddt.blocks[cfg[\"model\"][\"denoiser\"][\"init_args\"][\"num_encoder_blocks\"] - 1]\n",
    "\"\"\"\n",
    "h = layer.register_forward_hook(hook)\n",
    "_ = ddt(x, t, y)\n",
    "h.remove()\n",
    "print(\"Extracted features shape:\", feat[\"f\"].shape)\n",
    "\"\"\"\n",
    "\n",
    "# build dataloader\n",
    "transform = T.Compose([\n",
    "    T.Resize(256), T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "def preprocess(batch):\n",
    "    batch[\"imgs\"] = [transform(img.convert(\"RGB\")) for img in batch[\"image\"]]\n",
    "    return batch\n",
    "\n",
    "ds = load_dataset(\"imagenet-1k\", split=\"train\", streaming=True)\n",
    "ds = ds.shuffle(buffer_size=1000).map(preprocess, batched=True, batch_size=32)\n",
    "\n",
    "class Wrap(IterableDataset):\n",
    "    def __init__(self, ds): self.ds = ds\n",
    "    def __iter__(self):\n",
    "        for item in self.ds:\n",
    "            yield item[\"imgs\"], item[\"label\"]\n",
    "\n",
    "dataloader = DataLoader(Wrap(ds), batch_size=128, num_workers=2)\n",
    "print(\"Dataloader ready:\", next(iter(dataloader))[0].shape)\n",
    "\n",
    "# extract and save features\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s: %(message)s\")\n",
    "BATCH_SIZE = 128\n",
    "CHUNK = 100000\n",
    "SAVE_EVERY = CHUNK//BATCH_SIZE\n",
    "print(SAVE_EVERY)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# preset scheduler constants\n",
    "scheduler = getattr(model.module if isinstance(model, nn.DataParallel) else model, \n",
    "                    \"diffusion_trainer\", model).scheduler\n",
    "t0 = torch.tensor([0.95], device=device)\n",
    "a0 = scheduler.alpha(t0).view(-1,1,1,1)\n",
    "s0 = scheduler.sigma(t0).view(-1,1,1,1)\n",
    "\n",
    "hook_feats = {\"f\": None}\n",
    "def hook_fn(_,__,o):\n",
    "    hook_feats[\"f\"] = (o[0] if isinstance(o, tuple) else o).detach()\n",
    "\n",
    "HOOK_IDX = cfg[\"model\"][\"diffusion_trainer\"][\"init_args\"].get(\"num_encoder_blocks\", 22) - 1\n",
    "\n",
    "print(HOOK_IDX)\n",
    "blk = ddt.blocks[HOOK_IDX]\n",
    "h = blk.register_forward_hook(hook_fn)\n",
    "\n",
    "chunks, labs, toks = [], [], []\n",
    "cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T15:35:28.600944Z",
     "iopub.status.busy": "2025-06-19T15:35:28.600146Z",
     "iopub.status.idle": "2025-06-19T15:35:29.156332Z",
     "shell.execute_reply": "2025-06-19T15:35:29.155561Z",
     "shell.execute_reply.started": "2025-06-19T15:35:28.600914Z"
    }
   },
   "outputs": [],
   "source": [
    "# for when CUDA goes out of memory\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Clear CUDA cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Force garbage collection\n",
    "gc.collect()\n",
    "\n",
    "# Optional: Clear all cached memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extaction Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "NUM_SAMPLES = 1281167\n",
    "NUM_BATCHES = NUM_SAMPLES // BATCH_SIZE\n",
    "\n",
    "for i, (imgs, labs_batch) in enumerate(tqdm(dataloader, desc=\"Extracting Features\", total=NUM_BATCHES, leave=True)):\n",
    "    imgs = imgs.to(device)\n",
    "    labs_batch = labs_batch.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        z_raw = vae.encode(imgs)\n",
    "        z = z_raw.sample() if hasattr(z_raw, \"sample\") else z_raw\n",
    "        noise = torch.randn_like(z)\n",
    "        zt = a0 * z + s0 * noise\n",
    "        uncond = torch.full_like(labs_batch, cfg[\"model\"][\"denoiser\"][\"init_args\"].get(\"num_classes\", 1000))\n",
    "        out = ddt(zt, torch.full((z.shape[0],), 0.95, device=device, dtype=torch.long), uncond)\n",
    "\n",
    "        feats = hook_feats[\"f\"]\n",
    "        if feats is not None:\n",
    "            if feats.ndim == 4:\n",
    "                feats = feats.mean(dim=[2, 3])  # [B, C, H, W] → [B, C]\n",
    "            elif feats.ndim == 3:\n",
    "                feats = feats.mean(dim=1)       # [B, N, D] → [B, D]\n",
    "            elif feats.ndim == 2:\n",
    "                pass\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected feat shape: {feats.shape}\")\n",
    "    \n",
    "    chunks.append(feats.cpu())\n",
    "    labs.append(labs_batch.cpu())\n",
    "    toks.append(out[0].detach().cpu())\n",
    "    del z, zt, noise, out, feats\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    if (i + 1) % SAVE_EVERY == 0:\n",
    "        torch.save(torch.cat(chunks), os.path.join(OUTPUT_DIR, f\"feat_{cnt}.pt\"))\n",
    "        torch.save(torch.cat(labs), os.path.join(OUTPUT_DIR, f\"labs_{cnt}.pt\"))\n",
    "        torch.save(torch.cat(toks), os.path.join(OUTPUT_DIR, f\"toks_{cnt}.pt\"))\n",
    "        logging.info(f\"Saved chunk {cnt}\")\n",
    "        cnt += 1\n",
    "        chunks, labs, toks = [], [], []\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Features with a t-SNE Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tensors(pattern):\n",
    "    files = sorted(glob(pattern))\n",
    "    print(\"loading data\")\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No files match: {pattern}\")\n",
    "    return torch.cat([torch.load(f) for f in files])\n",
    "\n",
    "def reshape_if_needed(x):\n",
    "    return x.view(x.size(0), -1) if x.dim() != 2 else x\n",
    "\n",
    "def plot_tsne(data, labels, title, max_points=20000):\n",
    "    data = data.cpu()\n",
    "    labels = labels.cpu()\n",
    "\n",
    "    if data.size(0) > max_points:\n",
    "        idx = torch.randperm(data.size(0))[:max_points]\n",
    "        data = data[idx]\n",
    "        labels = labels[idx]\n",
    "\n",
    "    tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "    reduced = tsne.fit_transform(data)\n",
    "    labels_np = labels.numpy()\n",
    "\n",
    "    # Normalize labels to [0, 1] range for colormap\n",
    "    norm_labels = (labels_np - labels_np.min()) / (labels_np.max() - labels_np.min())\n",
    "    colors = cm.viridis(norm_labels)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(reduced[:, 0], reduced[:, 1], c=colors, s=5, alpha=0.7)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.colorbar(label='Class index (normalized)')\n",
    "    plt.show()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "base = 'extracted_features'\n",
    "feats = load_tensors(os.path.join(base, 'feat_*.pt'))\n",
    "toks = load_tensors(os.path.join(base, 'toks_*.pt'))\n",
    "labs = load_tensors(os.path.join(base, 'labs_*.pt')).long().squeeze()\n",
    "\n",
    "if feats.dim() == 4 and toks.dim() == 2:\n",
    "    feats, toks = toks, feats\n",
    "\n",
    "feats = reshape_if_needed(feats)\n",
    "toks = reshape_if_needed(toks)\n",
    "\n",
    "plot_tsne(feats, labs, \"t-SNE: Features + Labels\")\n",
    "plot_tsne(toks, labs, \"t-SNE: Tokens + Labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a Linear Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = F.normalize(torch.cat((feats, toks), dim=1), p=2, dim=1)\n",
    "\n",
    "if X.size(0) != labs.size(0):\n",
    "    print(\"Mismatch between features and labels.\")\n",
    "    \n",
    "\n",
    "try:\n",
    "    y_cpu = labs.cpu()\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, labs, test_size=0.2, stratify=y_cpu, random_state=42)\n",
    "except ValueError:\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, labs, test_size=0.2, random_state=42)\n",
    "\n",
    "model = nn.Linear(X_train.size(1), len(torch.unique(labs))).to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    perm = torch.randperm(X_train.size(0))\n",
    "    for i in range(0, X_train.size(0), 64):\n",
    "        idx = perm[i:i+64]\n",
    "        batch_X = X_train[idx].to(device)\n",
    "        batch_y = y_train[idx].to(device)\n",
    "        out = model(batch_X)\n",
    "        loss = loss_fn(out, batch_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_out = model(X_val.to(device))\n",
    "            val_loss = loss_fn(val_out, y_val.to(device))\n",
    "            acc = (val_out.argmax(1) == y_val.to(device)).float().mean().item() * 100\n",
    "            print(f\"Epoch {epoch+1}: Loss {loss.item():.4f}, Val Loss {val_loss.item():.4f}, Acc {acc:.2f}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
